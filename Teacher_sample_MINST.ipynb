{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e543ea-7424-4803-bc73-458d39edda99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.26.2)\n",
      "Collecting keras\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (1.11.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (10.1.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.11/site-packages (from keras) (3.10.0)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from keras) (23.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.66.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (1.13.0)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (2.0.23)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.66.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.1/349.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, opencv-python, ml-dtypes, mdurl, markdown, grpcio, google-pasta, gast, colorlog, astunparse, absl-py, tensorboard, markdown-it-py, rich, optuna, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 colorlog-6.8.2 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opencv-python-4.10.0.84 opt-einsum-3.4.0 optree-0.12.1 optuna-4.0.0 rich-13.8.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 werkzeug-3.0.4 wrapt-1.16.0\n",
      "Collecting git+https://github.com/cair/tmu.git\n",
      "  Cloning https://github.com/cair/tmu.git to /tmp/pip-req-build-0ikloe8l\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cair/tmu.git /tmp/pip-req-build-0ikloe8l\n",
      "  Resolved https://github.com/cair/tmu.git to commit df55ecb3c200b85489ac77fbb8d9a3bc9f7e0483\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.15.0 in /opt/conda/lib/python3.11/site-packages (from tmu==0.8.3) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from tmu==0.8.3) (1.26.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from tmu==0.8.3) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from tmu==0.8.3) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from tmu==0.8.3) (4.66.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from tmu==0.8.3) (2.31.0)\n",
      "Collecting xxhash (from tmu==0.8.3)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.15.0->tmu==0.8.3) (2.21)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->tmu==0.8.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->tmu==0.8.3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->tmu==0.8.3) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->tmu==0.8.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->tmu==0.8.3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->tmu==0.8.3) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->tmu==0.8.3) (2023.11.17)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->tmu==0.8.3) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->tmu==0.8.3) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->tmu==0.8.3) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->tmu==0.8.3) (1.16.0)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tmu\n",
      "  Building wheel for tmu (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tmu: filename=tmu-0.8.3-cp311-cp311-linux_x86_64.whl size=235660 sha256=9f96bc0d1973bccbdc1c5ca71a7715fa058e2f73a455e8ee73da3e980043b084\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cl460cp4/wheels/06/5c/00/d7505e35699e1e072d72b867af5ddd8d0882f3680213f34745\n",
      "Successfully built tmu\n",
      "Installing collected packages: xxhash, tmu\n",
      "  Attempting uninstall: tmu\n",
      "    Found existing installation: tmu 0.8.1\n",
      "    Uninstalling tmu-0.8.1:\n",
      "      Successfully uninstalled tmu-0.8.1\n",
      "Successfully installed tmu-0.8.3 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy keras tensorflow scikit-learn scipy tqdm pillow opencv-python optuna\n",
    "!pip install git+https://github.com/cair/tmu.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa969c43-1ab9-4095-83c4-044fe23bda0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cair/GraphTsetlinMachine.git\n",
      "  Cloning https://github.com/cair/GraphTsetlinMachine.git to /tmp/pip-req-build-jp47ecmq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cair/GraphTsetlinMachine.git /tmp/pip-req-build-jp47ecmq\n",
      "  Resolved https://github.com/cair/GraphTsetlinMachine.git to commit f2041cf6919ac54b193e48cc97f04cbac7591ed1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: GraphTsetlinMachine\n",
      "  Building wheel for GraphTsetlinMachine (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for GraphTsetlinMachine: filename=GraphTsetlinMachine-0.2.0-py3-none-any.whl size=12944 sha256=be3229d6de4e14c5b3ccc4305f9410d282e473964a86268f373b66c92c7a76fc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-low_e3qc/wheels/34/cc/e5/cd009a2fbcaf890e64951f3f7dc9df0cdece99f8c85b781178\n",
      "Successfully built GraphTsetlinMachine\n",
      "Installing collected packages: GraphTsetlinMachine\n",
      "Successfully installed GraphTsetlinMachine-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/cair/GraphTsetlinMachine.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e57a710b-7fff-469c-91d3-07cfba8d0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from time import time\n",
    "import argparse\n",
    "from skimage.util import view_as_windows\n",
    "from keras.datasets import mnist\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5a7e14-e41b-4df1-8f02-b678d4ea0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "X_train = np.where(X_train > 75, 1, 0)\n",
    "X_test = np.where(X_test > 75, 1, 0)\n",
    "Y_train = Y_train.astype(np.uint32)\n",
    "Y_test = Y_test.astype(np.uint32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df82632e-dad2-49f2-a943-92960ceb987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "Y_train.shape\n",
    "X_train[0].shape\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "895ec4c9-02d4-4dbb-8db3-3f03837bd929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:0',\n",
       " 'R:0',\n",
       " 'C:1',\n",
       " 'R:1',\n",
       " 'C:2',\n",
       " 'R:2',\n",
       " 'C:3',\n",
       " 'R:3',\n",
       " 'C:4',\n",
       " 'R:4',\n",
       " 'C:5',\n",
       " 'R:5',\n",
       " 'C:6',\n",
       " 'R:6',\n",
       " 'C:7',\n",
       " 'R:7',\n",
       " 'C:8',\n",
       " 'R:8',\n",
       " 'C:9',\n",
       " 'R:9',\n",
       " 'C:10',\n",
       " 'R:10',\n",
       " 'C:11',\n",
       " 'R:11',\n",
       " 'C:12',\n",
       " 'R:12',\n",
       " 'C:13',\n",
       " 'R:13',\n",
       " 'C:14',\n",
       " 'R:14',\n",
       " 'C:15',\n",
       " 'R:15',\n",
       " 'C:16',\n",
       " 'R:16',\n",
       " 'C:17',\n",
       " 'R:17',\n",
       " 'C:18',\n",
       " 'R:18',\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def default_args(**kwargs):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", default=250, type=int)\n",
    "    parser.add_argument(\"--number-of-clauses\", default=20000, type=int)\n",
    "    parser.add_argument(\"--T\", default=25000, type=int)\n",
    "    parser.add_argument(\"--s\", default=10.0, type=float)\n",
    "    parser.add_argument(\"--depth\", default=1, type=int)\n",
    "    parser.add_argument(\"--hypervector-size\", default=128, type=int)\n",
    "    parser.add_argument(\"--hypervector-bits\", default=2, type=int)\n",
    "    parser.add_argument(\"--message-size\", default=256, type=int)\n",
    "    parser.add_argument(\"--message-bits\", default=2, type=int)\n",
    "    parser.add_argument(\"--max-included-literals\", default=32, type=int)\n",
    "\n",
    "    # This will ignore any unrecognized arguments (like the `-f` from Jupyter)\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        if key in args.__dict__:\n",
    "            setattr(args, key, value)\n",
    "    \n",
    "    return args\n",
    "\n",
    "# Now you can call the args in the same way\n",
    "args = default_args()\n",
    "\n",
    "\n",
    "patch_size = 10\n",
    "dim = 28 - patch_size + 1\n",
    "\n",
    "number_of_nodes = dim * dim\n",
    "\n",
    "symbol_names = []\n",
    "\n",
    "# Column and row symbols\n",
    "for i in range(dim):\n",
    "    symbol_names.append(\"C:%d\" % (i))\n",
    "    symbol_names.append(\"R:%d\" % (i))\n",
    "\n",
    "# Patch pixel symbols\n",
    "for i in range(patch_size*patch_size):\n",
    "    symbol_names.append(i)\n",
    "symbol_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b78007-7f7d-476c-abc2-8ad2537b776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_train = Graphs(X_train.shape[0], symbol_names=symbol_names, hypervector_size=args.hypervector_size, hypervector_bits=args.hypervector_bits)\n",
    "for graph_id in range(X_train.shape[0]):\n",
    "    graphs_train.set_number_of_graph_nodes(graph_id, number_of_nodes)\n",
    "\n",
    "graphs_train.prepare_node_configuration()\n",
    "\n",
    "for graph_id in range(X_train.shape[0]):\n",
    "    for node_id in range(graphs_train.number_of_graph_nodes[graph_id]):\n",
    "        graphs_train.add_graph_node(graph_id, node_id, 0)\n",
    "\n",
    "graphs_train.prepare_edge_configuration()\n",
    "\n",
    "for graph_id in range(X_train.shape[0]):\n",
    "    if graph_id % 1000 == 0:\n",
    "        print(graph_id, X_train.shape[0])\n",
    "     \n",
    "    windows = view_as_windows(X_train[graph_id,:,:], (patch_size, patch_size))\n",
    "    for q in range(windows.shape[0]):\n",
    "            for r in range(windows.shape[1]):\n",
    "                node_id = q*dim + r\n",
    "\n",
    "                patch = windows[q,r].reshape(-1).astype(np.uint32)\n",
    "                for k in patch.nonzero()[0]:\n",
    "                    graphs_train.add_graph_node_feature(graph_id, node_id, k)\n",
    "\n",
    "                graphs_train.add_graph_node_feature(graph_id, node_id, \"C:%d\" % (q))\n",
    "                graphs_train.add_graph_node_feature(graph_id, node_id, \"R:%d\" % (r))\n",
    "\n",
    "graphs_train.encode()\n",
    "\n",
    "print(\"Training data produced\")\n",
    "\n",
    "graphs_test = Graphs(X_test.shape[0], init_with=graphs_train)\n",
    "for graph_id in range(X_test.shape[0]):\n",
    "    graphs_test.set_number_of_graph_nodes(graph_id, number_of_nodes)\n",
    "\n",
    "graphs_test.prepare_node_configuration()\n",
    "\n",
    "for graph_id in range(X_test.shape[0]):\n",
    "    for node_id in range(graphs_test.number_of_graph_nodes[graph_id]):\n",
    "        graphs_test.add_graph_node(graph_id, node_id, 0)\n",
    "\n",
    "graphs_test.prepare_edge_configuration()\n",
    "\n",
    "for graph_id in range(X_test.shape[0]):\n",
    "    if graph_id % 1000 == 0:\n",
    "        print(graph_id, X_test.shape[0])\n",
    "     \n",
    "    windows = view_as_windows(X_test[graph_id,:,:], (10, 10))\n",
    "    for q in range(windows.shape[0]):\n",
    "            for r in range(windows.shape[1]):\n",
    "                node_id = q*dim + r\n",
    "\n",
    "                patch = windows[q,r].reshape(-1).astype(np.uint32)\n",
    "                for k in patch.nonzero()[0]:\n",
    "                    graphs_test.add_graph_node_feature(graph_id, node_id, k)\n",
    "\n",
    "                graphs_test.add_graph_node_feature(graph_id, node_id, \"C:%d\" % (q))\n",
    "                graphs_test.add_graph_node_feature(graph_id, node_id, \"R:%d\" % (r))\n",
    "\n",
    "graphs_test.encode()\n",
    "\n",
    "print(\"Testing data produced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7fe2fa5-a0bf-4a68-a412-3b0a041412b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization of sparse structure.\n"
     ]
    }
   ],
   "source": [
    "tm = MultiClassGraphTsetlinMachine(args.number_of_clauses, args.T, args.s, depth=args.depth, message_size=args.message_size, message_bits=args.message_bits, max_included_literals=args.max_included_literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4511e4cc-364e-4083-97ef-5e75d5a2db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.04 13.50 44.75 3.08\n",
      "1 13.37 12.93 38.77 3.10\n",
      "2 13.46 13.22 37.89 3.09\n",
      "3 13.33 13.03 37.51 3.09\n",
      "4 13.28 13.32 37.28 3.09\n",
      "5 13.48 13.07 37.13 3.09\n",
      "6 12.93 12.61 37.02 3.09\n",
      "7 13.18 13.52 36.92 3.07\n",
      "8 13.31 13.37 36.89 3.09\n",
      "9 13.54 13.44 36.78 3.09\n",
      "10 13.44 13.32 36.69 3.09\n",
      "11 13.40 13.80 36.68 3.09\n",
      "12 13.15 13.11 36.63 3.09\n",
      "13 13.40 13.75 36.59 3.07\n",
      "14 13.43 12.82 36.60 3.09\n",
      "15 13.03 13.48 36.56 3.09\n",
      "16 13.10 13.17 36.57 3.07\n",
      "17 13.48 13.17 36.51 3.09\n",
      "18 13.35 13.25 36.48 3.09\n",
      "19 13.13 13.65 36.39 3.07\n",
      "20 13.18 13.15 36.43 3.09\n",
      "22 13.46 12.78 36.42 3.09\n",
      "23 13.38 13.10 36.35 3.09\n",
      "24 13.50 13.63 36.45 3.09\n",
      "25 13.11 13.26 36.35 3.09\n",
      "26 13.30 13.09 36.32 3.09\n",
      "27 13.23 13.47 36.35 3.09\n",
      "28 13.25 13.71 36.32 3.09\n",
      "29 13.49 13.86 36.35 3.09\n",
      "30 13.51 12.89 36.30 3.09\n",
      "31 13.36 12.53 36.31 3.09\n",
      "32 13.69 14.03 36.31 3.09\n",
      "33 13.26 12.85 36.35 3.09\n",
      "34 13.28 13.51 36.27 3.09\n",
      "36 13.29 13.13 36.25 3.08\n",
      "37 13.63 13.81 36.29 3.09\n",
      "38 13.34 13.14 36.22 3.08\n",
      "39 13.51 12.72 36.23 3.09\n",
      "40 13.47 12.74 36.28 3.10\n",
      "41 13.40 13.67 36.29 3.10\n",
      "42 13.26 13.45 36.24 3.09\n",
      "43 13.48 14.00 36.15 3.08\n",
      "44 13.23 14.12 36.25 3.09\n",
      "45 13.20 13.82 36.19 3.09\n",
      "46 13.15 13.63 36.20 3.07\n",
      "47 13.54 13.62 36.27 3.10\n",
      "48 13.21 13.19 36.21 3.09\n",
      "49 13.23 13.25 36.16 3.09\n",
      "51 13.68 13.05 36.26 3.09\n",
      "52 13.21 13.38 36.17 3.07\n",
      "53 13.45 13.42 36.21 3.07\n",
      "54 13.33 13.77 36.23 3.10\n",
      "55 14.08 13.99 36.20 3.09\n",
      "56 13.21 13.74 36.19 3.09\n",
      "57 13.47 13.74 36.17 3.07\n",
      "58 12.90 13.56 36.20 3.09\n",
      "59 13.44 12.98 36.22 3.09\n",
      "60 13.34 12.83 36.16 3.09\n",
      "61 13.11 13.38 36.13 3.09\n",
      "62 13.45 12.81 36.14 3.09\n",
      "63 13.43 13.35 36.12 3.09\n",
      "64 13.35 13.57 36.12 3.09\n",
      "65 13.42 13.53 36.06 3.09\n",
      "66 13.43 13.65 36.12 3.09\n",
      "67 13.35 13.41 36.11 3.09\n",
      "68 13.33 13.28 36.08 3.09\n",
      "69 13.88 13.51 36.09 3.09\n",
      "70 13.33 13.26 36.13 3.10\n",
      "71 13.36 13.42 36.09 3.09\n",
      "72 13.34 12.90 36.09 3.09\n",
      "73 13.52 13.87 36.03 3.09\n",
      "74 13.22 13.44 36.06 3.09\n",
      "75 13.51 13.07 36.12 3.09\n",
      "76 13.60 14.13 36.06 3.08\n",
      "77 13.28 12.86 36.08 3.08\n",
      "78 13.17 13.35 36.06 3.08\n",
      "79 13.25 13.53 36.10 3.09\n",
      "80 13.38 12.80 36.07 3.09\n",
      "81 13.47 13.77 36.08 3.09\n",
      "82 13.87 13.21 36.07 3.09\n",
      "83 13.33 13.74 36.07 3.09\n",
      "84 13.41 12.76 36.15 3.09\n",
      "85 13.46 13.64 36.06 3.09\n",
      "86 13.30 13.58 36.11 3.09\n",
      "87 13.17 13.54 36.10 3.09\n",
      "88 13.16 13.45 36.19 3.10\n",
      "89 13.42 13.89 36.16 3.10\n",
      "90 13.25 13.17 36.13 3.09\n",
      "91 12.88 13.19 36.07 3.09\n",
      "92 13.48 13.24 36.09 3.09\n",
      "93 13.49 12.67 36.07 3.07\n",
      "94 13.50 13.69 36.21 3.10\n",
      "95 13.51 13.51 36.15 3.10\n",
      "96 13.34 13.16 36.12 3.09\n",
      "97 13.17 13.48 36.08 3.09\n",
      "98 13.72 13.64 36.06 3.09\n",
      "99 13.31 13.02 36.11 3.09\n",
      "100 13.28 13.39 36.04 3.09\n",
      "101 13.56 13.52 36.12 3.10\n",
      "102 13.49 13.45 36.08 3.10\n",
      "103 13.50 13.40 36.07 3.09\n",
      "104 13.43 13.10 36.04 3.10\n",
      "105 13.39 13.25 36.04 3.09\n",
      "106 13.51 13.03 36.03 3.07\n",
      "107 13.27 12.97 36.06 3.09\n",
      "108 13.42 13.49 36.06 3.09\n",
      "109 12.88 13.30 36.02 3.09\n",
      "110 13.14 12.79 36.05 3.12\n",
      "111 13.46 13.80 36.08 3.09\n",
      "112 13.76 13.97 36.08 3.10\n",
      "113 12.97 13.27 36.12 3.09\n",
      "114 12.88 12.75 36.13 3.10\n",
      "115 13.66 13.32 36.18 3.08\n",
      "116 13.36 13.66 36.15 3.09\n",
      "117 13.51 13.45 36.11 3.10\n",
      "118 13.60 13.05 36.06 3.10\n",
      "119 13.15 13.28 36.06 3.07\n",
      "120 13.33 13.01 36.06 3.07\n",
      "121 13.20 13.07 36.04 3.07\n",
      "122 13.17 13.52 36.03 3.09\n",
      "123 13.51 14.06 36.05 3.09\n",
      "124 12.96 13.12 36.06 3.09\n",
      "125 13.11 13.83 36.01 3.10\n",
      "126 13.29 13.05 36.11 3.10\n",
      "127 13.25 13.66 36.07 3.10\n",
      "128 13.33 13.25 36.04 3.09\n",
      "129 13.08 12.95 36.05 3.10\n",
      "130 13.41 13.24 36.07 3.09\n",
      "131 13.48 13.29 36.09 3.09\n",
      "132 13.29 13.39 36.06 3.10\n",
      "133 13.27 13.37 36.09 3.09\n",
      "134 12.88 12.74 36.11 3.07\n",
      "135 13.65 13.97 36.10 3.10\n",
      "136 13.30 13.43 36.08 3.09\n",
      "137 13.05 13.63 36.11 3.09\n",
      "138 13.60 13.96 36.06 3.07\n",
      "139 13.68 14.20 36.03 3.07\n",
      "140 13.14 13.37 36.06 3.07\n",
      "141 13.46 13.55 36.03 3.10\n",
      "142 13.43 13.64 36.03 3.10\n",
      "143 13.16 13.00 36.04 3.10\n",
      "144 13.35 13.60 36.05 3.09\n",
      "145 13.46 13.42 36.02 3.10\n",
      "146 13.57 13.17 36.03 3.09\n",
      "147 13.22 13.45 36.01 3.09\n",
      "148 13.55 13.50 36.00 3.10\n",
      "149 13.36 12.98 35.97 3.09\n",
      "150 13.41 13.28 36.00 3.09\n",
      "151 13.27 12.61 36.08 3.10\n",
      "152 13.15 13.41 36.03 3.09\n",
      "153 13.21 13.51 35.91 3.09\n",
      "154 13.61 12.84 35.96 3.08\n",
      "155 13.33 13.41 35.96 3.09\n",
      "156 13.47 13.26 35.98 3.10\n",
      "157 13.44 13.50 35.99 3.09\n",
      "158 13.33 13.03 35.95 3.09\n",
      "159 13.19 13.48 35.98 3.09\n",
      "160 13.44 13.44 36.01 3.09\n",
      "161 13.45 13.57 35.99 3.09\n",
      "162 13.57 13.29 36.00 3.09\n",
      "163 13.21 13.34 35.96 3.07\n",
      "164 13.07 13.46 36.01 3.09\n",
      "165 13.04 13.24 35.97 3.09\n",
      "166 13.31 13.67 35.92 3.06\n",
      "167 13.29 13.47 35.94 3.09\n",
      "168 13.22 13.13 35.98 3.08\n",
      "169 13.35 13.66 35.91 3.08\n",
      "170 13.39 12.84 35.97 3.09\n",
      "171 13.46 13.67 35.97 3.09\n",
      "172 13.51 13.05 35.92 3.09\n",
      "173 13.14 13.19 35.98 3.09\n",
      "174 13.29 13.37 35.91 3.08\n",
      "175 12.71 13.01 35.98 3.08\n",
      "176 13.33 13.09 35.95 3.09\n",
      "177 13.22 13.16 36.04 3.09\n",
      "178 13.32 13.45 36.00 3.09\n",
      "179 13.36 13.08 36.00 3.09\n",
      "180 12.84 12.65 36.00 3.09\n",
      "181 13.29 13.68 35.97 3.09\n",
      "182 13.34 13.58 36.00 3.10\n",
      "183 13.31 13.04 35.98 3.09\n",
      "184 13.36 13.59 36.01 3.09\n",
      "185 13.32 13.45 36.01 3.09\n",
      "186 13.30 13.76 36.02 3.09\n",
      "187 13.38 13.80 35.96 3.07\n",
      "188 13.23 13.23 36.02 3.09\n",
      "189 13.23 13.87 36.06 3.11\n",
      "190 13.42 13.42 36.08 3.10\n",
      "191 13.46 12.56 36.02 3.09\n",
      "192 13.44 13.42 35.98 3.09\n",
      "193 13.29 13.08 35.95 3.09\n",
      "194 13.15 13.32 35.93 3.09\n",
      "195 13.29 13.32 35.96 3.09\n",
      "196 13.36 13.41 35.94 3.09\n",
      "197 13.23 13.49 35.96 3.09\n",
      "198 13.61 13.25 35.98 3.09\n",
      "199 13.38 13.32 35.99 3.10\n",
      "200 13.28 13.18 35.94 3.09\n",
      "201 13.09 13.18 35.97 3.09\n",
      "202 13.80 13.43 36.01 3.09\n",
      "203 13.48 13.71 35.94 3.09\n",
      "204 13.06 13.61 35.89 3.08\n",
      "205 13.70 13.57 35.87 3.08\n",
      "206 13.51 13.57 35.86 3.06\n",
      "207 13.09 13.01 35.90 3.09\n",
      "208 12.89 13.93 35.90 3.09\n",
      "209 13.18 13.41 35.85 3.06\n",
      "210 13.23 13.32 35.90 3.09\n",
      "211 13.53 13.66 35.91 3.09\n",
      "212 13.47 13.63 35.85 3.06\n",
      "213 13.22 13.95 35.92 3.09\n",
      "214 13.39 13.46 35.93 3.08\n",
      "215 13.61 13.57 35.89 3.06\n",
      "216 13.17 13.70 35.92 3.08\n",
      "217 13.37 13.68 35.92 3.09\n",
      "218 13.88 13.60 35.94 3.08\n",
      "219 13.51 13.19 35.89 3.09\n",
      "220 13.55 13.39 35.89 3.08\n",
      "221 13.16 13.47 35.90 3.08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m      2\u001b[0m     start_training \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     stop_training \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      6\u001b[0m     start_testing \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/GraphTsetlinMachine/tm.py:508\u001b[0m, in \u001b[0;36mMultiClassGraphTsetlinMachine.fit\u001b[0;34m(self, graphs, Y, epochs, incremental)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_outputs):\n\u001b[1;32m    506\u001b[0m \tencoded_Y[:,i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(Y \u001b[38;5;241m==\u001b[39m i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincremental\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/GraphTsetlinMachine/tm.py:388\u001b[0m, in \u001b[0;36mCommonTsetlinMachine._fit\u001b[0;34m(self, graphs, encoded_Y, epochs, incremental)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# Update clause Tsetlin automata blocks for layer one\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate\u001b[38;5;241m.\u001b[39mprepared_call(\n\u001b[1;32m    378\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid,\n\u001b[1;32m    379\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_clause_update_gpu\n\u001b[1;32m    387\u001b[0m )\n\u001b[0;32m--> 388\u001b[0m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Update clause Tsetlin automata blocks for deeper layers\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(args.epochs):\n",
    "    start_training = time()\n",
    "    tm.fit(graphs_train, Y_train, epochs=1, incremental=True)\n",
    "    stop_training = time()\n",
    "\n",
    "    start_testing = time()\n",
    "    result_test = 100*(tm.predict(graphs_test) == Y_test).mean()\n",
    "    stop_testing = time()\n",
    "\n",
    "    result_train = 100*(tm.predict(graphs_train) == Y_train).mean()\n",
    "\n",
    "    print(\"%d %.2f %.2f %.2f %.2f\" % (i, result_train, result_test, stop_training-start_training, stop_testing-start_testing))\n",
    "\n",
    "weights = tm.get_state()[1].reshape(2, -1)\n",
    "for i in range(tm.number_of_clauses):\n",
    "        print(\"Clause #%d W:(%d %d)\" % (i, weights[0,i], weights[1,i]), end=' ')\n",
    "        l = []\n",
    "        for k in range(args.hypervector_size * 2):\n",
    "            if tm.ta_action(0, i, k):\n",
    "                if k < args.hypervector_size:\n",
    "                    l.append(\"x%d\" % (k))\n",
    "                else:\n",
    "                    l.append(\"NOT x%d\" % (k - args.hypervector_size))\n",
    "        print(\" AND \".join(l))\n",
    "\n",
    "\n",
    "start_training = time()\n",
    "tm.fit(graphs_train, Y_train, epochs=1, incremental=True)\n",
    "stop_training = time()\n",
    "\n",
    "start_testing = time()\n",
    "result_test = 100*(tm.predict(graphs_test) == Y_test).mean()\n",
    "stop_testing = time()\n",
    "\n",
    "result_train = 100*(tm.predict(graphs_train) == Y_train).mean()\n",
    "\n",
    "print(\"%.2f %.2f %.2f %.2f\" % (result_train, result_test, stop_training-start_training, stop_testing-start_testing))\n",
    "\n",
    "print(graphs_train.hypervectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46f8bf-49bf-4304-9e98-8363047dfbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
